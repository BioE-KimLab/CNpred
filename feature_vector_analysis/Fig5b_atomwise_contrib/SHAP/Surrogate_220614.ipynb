{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60591c9d-22f1-4984-8e42-18f074c82243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "import shap\n",
    "shap.explainers._deep.deep_tf.op_handlers['AddV2'] = shap.explainers._deep.deep_tf.passthrough\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#from tensorflow.compat.v1.keras.backend import get_session\n",
    "#tf.compat.v1.disable_v2_behavior()\n",
    "#tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9620b98-0eed-4eb5-8246-73cb1a410f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_CN(num_atoms_of_interest):\n",
    "    df = pd.read_csv('molecules_to_predict.csv')\n",
    "    df['total_atoms'] = [ Chem.MolFromSmiles(smi).GetNumHeavyAtoms() for smi in df.Canonical_SMILES]\n",
    "    indices_of_interest = df[ df['total_atoms'] == num_atoms_of_interest ].index\n",
    "\n",
    "    with open('weights_last_layer.pkl','rb') as f:\n",
    "        #CN_readout, norelu, relu\n",
    "        w1, w2, w3 = pickle.load(f)\n",
    "\n",
    "    with open('feat_vectors_for_shap.pkl','rb') as f:\n",
    "        af_pkl, gf_pkl = pickle.load(f)\n",
    "\n",
    "    af_pkl = af_pkl[indices_of_interest][:, 0:num_atoms_of_interest]\n",
    "    gf_pkl = gf_pkl[indices_of_interest]\n",
    "\n",
    "    df = df[ df['total_atoms'] == num_atoms_of_interest ]\n",
    "    \n",
    "    #af_input = layers.Input(shape=[num_atoms_of_interest,64], dtype=tf.float32, name='af')\n",
    "    af_input = layers.Input(shape=[64], dtype=tf.float32, name='af')\n",
    "    gf_input = layers.Input(shape=[64], dtype=tf.float32, name='gf')\n",
    "\n",
    "    #af = layers.GlobalAveragePooling1D()(af_input)\n",
    "    af = layers.Dense(64, activation='relu', name = 'denserelu')(af_input)\n",
    "    af = layers.Dense(64, name = 'dense')(af)\n",
    "    gf = layers.Add()([gf_input, af])\n",
    "    prediction = layers.Dense(1, name = 'dense_final')(gf)\n",
    "    \n",
    "    input_tensors = [af_input, gf_input]\n",
    "    model = tf.keras.Model(input_tensors, [prediction])\n",
    "    \n",
    "    model.layers[-1].set_weights( [w1[0].numpy(), w1[1].numpy()] )\n",
    "    model.layers[-3].set_weights( [w2[0].numpy(), w2[1].numpy()] )\n",
    "    model.layers[-5].set_weights( [w3[0].numpy(), w3[1].numpy()] )\n",
    "\n",
    "    af_pkl_avg = np.mean(af_pkl, axis = 1)\n",
    "    pred = model.predict([af_pkl_avg, gf_pkl]).squeeze()\n",
    "    \n",
    "    print(np.abs(pred -  df.predicted).mean(), np.abs(pred -  df.predicted).max())\n",
    "    \n",
    "    #### SHAP part ####\n",
    "    e = shap.DeepExplainer(model, [af_pkl_avg, gf_pkl])\n",
    "    shap_values = e.shap_values([af_pkl_avg, gf_pkl])\n",
    "    \n",
    "    af_shap, gf_shap = shap_values[0]\n",
    "    \n",
    "    all_shap = af_shap + gf_shap\n",
    "    \n",
    "    atomwise_shap = np.zeros((len(df), num_atoms_of_interest, 64))\n",
    "    for i in range(len(af_pkl)): # af: (Num_atoms_in_a_molecule * 64)\n",
    "        for j in range(len(af_pkl[i])):  # Num_atoms_in_a_molecule\n",
    "            for k in range(len(af_pkl[i][j])): # 64\n",
    "                #atomwise_shap[i][j][k] = (af_pkl[i][j][k] / (num_atoms_of_interest * af_pkl_avg[i][k])) * af_shap[i][k]    \n",
    "                atomwise_shap[i][j][k] = (af_pkl[i][j][k] / (num_atoms_of_interest * af_pkl_avg[i][k])) * all_shap[i][k]    \n",
    "                \n",
    "    # for atom color map plot\n",
    "    atomwise_shap_for_plot = np.sum(atomwise_shap, axis = 2)\n",
    "    \n",
    "    # to find the ax+b correlation between af_shap + gf_shap vs. predicted CN\n",
    "    af_shap_summed = np.sum(af_shap, axis = 1)\n",
    "    gf_shap_summed = np.sum(gf_shap, axis = 1)\n",
    "    \n",
    "    total_shap = af_shap_summed + gf_shap_summed\n",
    "    \n",
    "    reg = LinearRegression().fit(total_shap.reshape(-1,1), df.predicted)\n",
    "    #print(num_atoms_of_interest, reg.coef_, reg.intercept_, reg.score(total_shap.reshape(-1,1), df.predicted))\n",
    "    \n",
    "    a, b  = reg.coef_[0], reg.intercept_\n",
    "    af_shap_normalized_to_CN = a * af_shap_summed + (b/2)\n",
    "    gf_shap_normalized_to_CN = a * gf_shap_summed + (b/2)\n",
    "    \n",
    "    atomwise_shap_normalized_to_CN = np.multiply(atomwise_shap_for_plot,\n",
    "                                                  np.tile(\n",
    "                                                      np.expand_dims(\n",
    "                                                          np.divide(  np.array(df.predicted), \n",
    "                                                                      np.sum(atomwise_shap_for_plot, axis = -1)\n",
    "                                                                   ), \n",
    "                                                       axis = 1),\n",
    "                                                  num_atoms_of_interest))\n",
    "    atom_shap_total = np.sum(atomwise_shap_normalized_to_CN, axis = -1)\n",
    "    return df, atomwise_shap_normalized_to_CN, atom_shap_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cb8961-dbd2-464f-b11e-10b9dc0d07e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9231015719738832e-06 1.335449218231588e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.670873232012304e-06 2.387451172580768e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.432051561199441e-06 9.344482421624889e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6005653246407032e-06 2.1198730465243898e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14adf002e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4.356046109455248e-06 4.878417968257054e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ae500eb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4.449384034259652e-06 3.473632813211225e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad681a04c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2.950825051731113e-06 1.0954589839684559e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14adf002ec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3.5141292857694576e-06 1.5322021482688797e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad681a0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3.894559860301294e-06 1.8078613280181344e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad140748b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4.720552571650198e-06 2.3002929687265805e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14adf002e8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4.981856281816022e-06 1.8763427732437776e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad140749d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6.762483724050602e-06 1.838134765819177e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ae5004a4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5.767883299601095e-06 1.831054687784217e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad681a0af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4.966895918354843e-06 1.5246582037775624e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad681a0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3.7810959596757107e-06 1.5653320318165242e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ae500d08b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4.944732664435847e-06 1.6982421868760866e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14ad140743a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5.437627155953824e-06 2.4577636722256102e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('molecules_to_predict.csv')\n",
    "df['total_atoms'] = [ Chem.MolFromSmiles(smi).GetNumHeavyAtoms() for smi in df.Canonical_SMILES]\n",
    "df_w_shap = pd.DataFrame(columns = list(df.columns) + ['atom_shap_total','atomwise_shap'])\n",
    "\n",
    "for i in range(8,25):\n",
    "#for i in range(8,9):\n",
    "    df_sub, atomwise_shap, atom_shap_total = shap_CN(i)\n",
    "    df_sub['atomwise_shap'] = list(atomwise_shap)\n",
    "    df_sub['atom_shap_total'] = list(atom_shap_total)\n",
    "    df_w_shap = pd.concat([df_w_shap, df_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c403701c-6890-4ffd-8798-0a3d6d7bfffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nimport matplotlib\\n\\nimport seaborn as sns\\nsns.set(context=\\'talk\\', style=\\'ticks\\',\\n        color_codes=True, rc={\\'legend.frameon\\': False})\\n%matplotlib inline\\n\\nmatplotlib.rcParams[\\'figure.dpi\\'] = 300\\n#plt.rcParams[\"font.family\"] = \\'Arial\\'\\n#plt.rcParams.update({\\'font.size\\': 24})\\n\\nplt.scatter(af_shap_summed + gf_shap_summed, df.predicted)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 300\n",
    "#plt.rcParams[\"font.family\"] = 'Arial'\n",
    "#plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "plt.scatter(af_shap_summed + gf_shap_summed, df.predicted)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba8842e-2357-4e52-9dbc-ad6ce0a327a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical_SMILES</th>\n",
       "      <th>Device_tier</th>\n",
       "      <th>Train/Valid/Test</th>\n",
       "      <th>CN</th>\n",
       "      <th>predicted</th>\n",
       "      <th>glob_vector</th>\n",
       "      <th>total_atoms</th>\n",
       "      <th>atom_shap_total</th>\n",
       "      <th>atomwise_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C1CC=CCCC=C1</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>25.7</td>\n",
       "      <td>25.178371</td>\n",
       "      <td>1.279825 6.559031 -3.800939 -1.587972 1.457567...</td>\n",
       "      <td>8</td>\n",
       "      <td>25.178371</td>\n",
       "      <td>[3.1698394378240833, 3.1698394378240833, 3.124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>COc1ccccc1</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.952137</td>\n",
       "      <td>0.297395 2.443781 -1.300710 -0.222946 0.281806...</td>\n",
       "      <td>8</td>\n",
       "      <td>5.952137</td>\n",
       "      <td>[0.9108201797130551, 1.0394858541399652, 0.932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CCCCC(C)CC</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.368923</td>\n",
       "      <td>2.267500 11.448519 -7.420034 -3.916420 2.46237...</td>\n",
       "      <td>8</td>\n",
       "      <td>46.368923</td>\n",
       "      <td>[4.8671194106524815, 13.378437286900466, -0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CCCCCC(C)C</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>52.6</td>\n",
       "      <td>53.743870</td>\n",
       "      <td>2.649966 13.292315 -8.495021 -4.692094 2.94048...</td>\n",
       "      <td>8</td>\n",
       "      <td>53.743870</td>\n",
       "      <td>[2.789452487661217, 5.362448544461024, 7.05991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CC1=CC(=CC=C1)C</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.101751</td>\n",
       "      <td>0.114691 2.321426 -1.313794 -0.092019 0.266234...</td>\n",
       "      <td>8</td>\n",
       "      <td>7.101751</td>\n",
       "      <td>[0.3512299984009973, 1.472342742429441, 0.3305...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>O(C(=O)CCCCCCCC=CCCCCCCCC)C(C)CC</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.144760</td>\n",
       "      <td>3.250906 17.743423 -10.671388 -5.775561 3.9041...</td>\n",
       "      <td>24</td>\n",
       "      <td>69.144760</td>\n",
       "      <td>[2.4940025036433457, 1.4305945791904493, 0.424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>CCCCOC(=O)CCCCCCC/C=C/C/C=C/C/C=C/CC</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.940542</td>\n",
       "      <td>1.226841 7.070701 -4.538584 -2.350751 1.198096...</td>\n",
       "      <td>24</td>\n",
       "      <td>28.940542</td>\n",
       "      <td>[0.9716006150550872, 2.356929163283433, 2.3697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>CCCCOC(=O)CCCCCCCC=CCC=CCC=CCC</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.940540</td>\n",
       "      <td>1.226841 7.070702 -4.538585 -2.350750 1.198097...</td>\n",
       "      <td>24</td>\n",
       "      <td>28.940540</td>\n",
       "      <td>[0.9716004844608673, 2.356928512211588, 2.3697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>CCCCCCCCC(CCC)C(CCC)CCCCCCCC</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.491978</td>\n",
       "      <td>2.486418 10.892790 -6.722002 -3.544846 2.27920...</td>\n",
       "      <td>24</td>\n",
       "      <td>44.491978</td>\n",
       "      <td>[1.1879794266889057, 1.712365627548747, 2.1823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>CCCCCCOC(=O)C1=CC=CC=C1C(=O)OCCCCCC</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.116280</td>\n",
       "      <td>1.885477 14.634890 -7.869594 -3.706099 2.03854...</td>\n",
       "      <td>24</td>\n",
       "      <td>46.116280</td>\n",
       "      <td>[1.1683711559199157, 1.9594758209062013, 2.694...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Canonical_SMILES Device_tier Train/Valid/Test    CN  \\\n",
       "9                            C1CC=CCCC=C1           1            Train  25.7   \n",
       "30                             COc1ccccc1           1            Train   6.2   \n",
       "43                             CCCCC(C)CC           1            Train  45.0   \n",
       "64                             CCCCCC(C)C           1            Train  52.6   \n",
       "73                        CC1=CC(=CC=C1)C           1            Train   7.0   \n",
       "..                                    ...         ...              ...   ...   \n",
       "496      O(C(=O)CCCCCCCC=CCCCCCCCC)C(C)CC           3            Train  72.0   \n",
       "525  CCCCOC(=O)CCCCCCC/C=C/C/C=C/C/C=C/CC           1            Valid  28.6   \n",
       "614        CCCCOC(=O)CCCCCCCC=CCC=CCC=CCC           3             Test  29.0   \n",
       "621          CCCCCCCCC(CCC)C(CCC)CCCCCCCC           3             Test  47.0   \n",
       "627   CCCCCCOC(=O)C1=CC=CC=C1C(=O)OCCCCCC           3             Test  48.0   \n",
       "\n",
       "     predicted                                        glob_vector total_atoms  \\\n",
       "9    25.178371  1.279825 6.559031 -3.800939 -1.587972 1.457567...           8   \n",
       "30    5.952137  0.297395 2.443781 -1.300710 -0.222946 0.281806...           8   \n",
       "43   46.368923  2.267500 11.448519 -7.420034 -3.916420 2.46237...           8   \n",
       "64   53.743870  2.649966 13.292315 -8.495021 -4.692094 2.94048...           8   \n",
       "73    7.101751  0.114691 2.321426 -1.313794 -0.092019 0.266234...           8   \n",
       "..         ...                                                ...         ...   \n",
       "496  69.144760  3.250906 17.743423 -10.671388 -5.775561 3.9041...          24   \n",
       "525  28.940542  1.226841 7.070701 -4.538584 -2.350751 1.198096...          24   \n",
       "614  28.940540  1.226841 7.070702 -4.538585 -2.350750 1.198097...          24   \n",
       "621  44.491978  2.486418 10.892790 -6.722002 -3.544846 2.27920...          24   \n",
       "627  46.116280  1.885477 14.634890 -7.869594 -3.706099 2.03854...          24   \n",
       "\n",
       "     atom_shap_total                                      atomwise_shap  \n",
       "9          25.178371  [3.1698394378240833, 3.1698394378240833, 3.124...  \n",
       "30          5.952137  [0.9108201797130551, 1.0394858541399652, 0.932...  \n",
       "43         46.368923  [4.8671194106524815, 13.378437286900466, -0.48...  \n",
       "64         53.743870  [2.789452487661217, 5.362448544461024, 7.05991...  \n",
       "73          7.101751  [0.3512299984009973, 1.472342742429441, 0.3305...  \n",
       "..               ...                                                ...  \n",
       "496        69.144760  [2.4940025036433457, 1.4305945791904493, 0.424...  \n",
       "525        28.940542  [0.9716006150550872, 2.356929163283433, 2.3697...  \n",
       "614        28.940540  [0.9716004844608673, 2.356928512211588, 2.3697...  \n",
       "621        44.491978  [1.1879794266889057, 1.712365627548747, 2.1823...  \n",
       "627        46.116280  [1.1683711559199157, 1.9594758209062013, 2.694...  \n",
       "\n",
       "[514 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532e4006-5d85-43aa-b446-5931af288367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_shap.to_csv('CN_shap_220614.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c18c5-f14b-4a82-aed5-95cc6b965975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
